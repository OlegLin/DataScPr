{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1kORKaMmvrqejujKk2hFMKvbYXc4rmLxH","timestamp":1640641942766}],"collapsed_sections":["A7BEraabhWFC"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","source":["# Семинар 3\n","## Вычислительная линейная алгебра"],"metadata":{"id":"nBFX-rqpB4t4"}},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-20T09:04:25.887129Z","start_time":"2021-02-20T09:04:24.096021Z"},"id":"6Oz4d6jcq5Fj"},"source":["# Импортируем все библиотеки, которые нам сегодня понадобятся\n","import os\n","\n","import pandas as pd\n","import numpy as np\n","import scipy as sp\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.decomposition import PCA"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Настроим библиотеки отрисовки\n","%matplotlib inline\n","\n","sns.set(font_scale=1.3)\n","\n","red   = '#FF3300'\n","blue  = '#0099CC'\n","green = '#00CC66'"],"metadata":{"id":"QMz2FVunHVh-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["На этом занятии мы:\n","* Вспомним как работать с векторами и матрицами в numpy\n","* Посмотрим как пользоваться SVD разложением\n","* Посмотрим как пользоваться PCA\n","* Применим PCA для сжатия изображения\n","* Применим PCA в задаче классификации для уменьшения размера признакового пространства"],"metadata":{"id":"9d7d3yIoBvLx"}},{"cell_type":"markdown","source":["## 0. Работа с матрицами"],"metadata":{"id":"k7hhYU6YD9Nj"}},{"cell_type":"code","source":["# Создадим при помощи numpy две матрицы 2х2, одну матрицу 2х3 и два вектора длины 2 и один вектор длин 3 с произвольными числами\n","\n","A = np.array([[1,2],\n","              [3,-4]])\n","B = np.array([[2, 0],\n","              [0, 1]])\n","C = np.array([[1, -2, 0],\n","              [3, 0, -1]])\n","\n","x = np.array([1, -1])\n","y = np.array([2, 1])\n","z = np.array([1, 4, 2])"],"metadata":{"id":"kAqJ5lqDEBWp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Умножение матриц и векторов"],"metadata":{"id":"tJOqNN9wJZir"}},{"cell_type":"code","source":["# Посчитаем что получится при поэлементном умножении матриц A и B (*)\n","\n","print(...)"],"metadata":{"id":"mBx09_xjIDxz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Посчитаем что получится при математическом умножении матриц A и B (@ или np.dot)\n","\n","print(...)"],"metadata":{"id":"_4Nim-StID0G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Посчитаем что получится при математическом умножении матриц A и C (@ или np.dot)\n","\n","print(...)"],"metadata":{"id":"ZwusyoijID2d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Получится ли умножить матрицу C на матрицу A?\n","\n","print(...)"],"metadata":{"id":"R9x4ZQjxJWuV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Умножим матрицу A на вектор x справа и слева математически (@ или np.dot)\n","\n","print(...)\n","print(...)"],"metadata":{"id":"nzRw3fv-J4Hj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Умножим матрицу C на вектор z справа математически (@ или np.dot)\n","\n","print(...)\n","\n","# Получится ли у нас умножить слева?\n","print(...)"],"metadata":{"id":"X9u4UDrqJ4OB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Умножим математически вектор x и y\n","\n","print(...)"],"metadata":{"id":"MA-uXvUkJ4fM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Если хочется еще что-то поумножать, то можем попрактиковаться:)\n","..."],"metadata":{"id":"sivAGZ4WJWw5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Полезные матрицы"],"metadata":{"id":"gO6G-5ZHL3H4"}},{"cell_type":"code","source":["# Единичная матрица (np.eye)\n","\n","print(...)"],"metadata":{"id":"3NmcuKr7L2Zz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Матрица из единиц (np.ones)\n","\n","print(...)"],"metadata":{"id":"fyOPnrhRL-29"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Матрица из нулей (np.zeros)\n","\n","print(...)"],"metadata":{"id":"NRzJw6fzL2tV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Диагональная матрица (np.diag)\n","\n","print(...)"],"metadata":{"id":"_H7N6-LUME3k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Полезные функции"],"metadata":{"id":"oJQFuynmLfm8"}},{"cell_type":"code","source":["# Определитель [применим на матрицы A и B] (np.linalg.det)\n","\n","print(...)\n","print(...)\n","\n","# Что если применить на матрице C\n","print(...)"],"metadata":{"id":"YWHSVo2DID4y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Собственные вектора и значения [применим на матрицу B] (np.linalg.eigh)\n","\n","print(...)\n","\n","# Можно ли применить на матрицу C?"],"metadata":{"id":"N_lEl_g9LqzF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Обратная матрица [применим на матрицы A и B] (np.linalg.inv)\n","\n","print(...)\n","print(...)"],"metadata":{"id":"DEJzjq4oLq17"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Проверим, что она действительно обратная. Как мы можем это сделать?\n","\n","print(...)\n","print(...)"],"metadata":{"id":"F7vThU7RN8_I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xcK2IlpNq5GD"},"source":["## 1. SVD-разложение"]},{"cell_type":"markdown","metadata":{"id":"63U95Rvzq5GF"},"source":["Для того, чтобы ручками потрогать SVD разложение, воспользуемся его реализацией в scipy и сгенерированным датасетом."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-20T09:04:25.907915Z","start_time":"2021-02-20T09:04:25.890467Z"},"id":"bV07mCsFq5GF"},"source":["# Сгенерируем матрицу размера 100 на 10 из нормального распределения при помощи функции normal модуля random\n","X = ...\n","print(X.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-20T09:04:25.932560Z","start_time":"2021-02-20T09:04:25.910894Z"},"id":"6BLrmpA4q5GN"},"source":["# Воспользуемся функцией svd модуля linalg библиотеки scipy для того, чтобы получить svd разложение нашей матрицы X\n","# У этой функции есть параметр full_matrices, предлагается попробовать оба варианта значения этого параметра, чтобы понять, что он изменяет\n","\n","U, D, V = ...\n","print(U.shape, D.shape, V.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Посмотрим, что из себя представляет матрица D\n","\n","print(...)"],"metadata":{"id":"viFbWvzhZzOc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Переведем D в матричный вид при помощи умножения на единичную матрицу поэлементно (*)\n","\n","print(...)"],"metadata":{"id":"Jos3nHxaZwS2"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-20T09:04:25.940295Z","start_time":"2021-02-20T09:04:25.934210Z"},"id":"wDVSij_OsGCf"},"source":["# Проверим, что SVD работает верно, умножив последовательно матрицы U, D и V\n","X_restored = ...\n","\n","print(np.allclose(X_restored, X))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HQg-ABMreVMg"},"source":["Восстановленная версия действительно очень близка к исходной."]},{"cell_type":"markdown","metadata":{"id":"xR03V00iq5GQ"},"source":["## 2. PCA (Principal component analysis)\n","\n","### Метод главных компонент\n","\n","Интерактивная визуализация PCA и собственных векторов:\n","\n","* <a href=\"http://setosa.io/ev/principal-component-analysis/\">Principal Component Analysis</a>\n","\n","* <a href=\"http://setosa.io/ev/eigenvectors-and-eigenvalues/\">Eigenvectors and Eigenvalues</a>\n","\n"]},{"cell_type":"markdown","source":["\n","\n","Реализация из sklearn:\n","\n","<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA\">`sklearn.decomposition.PCA`</a>`(n_components=None)`\n","\n","Методы класса:\n","* `fit(X)` — обучиться на данных `X`;\n","* `fit_transforn(X)` — обучиться на данных `X` и вернуть сжатое представление `X`;\n","* `transform(X_new)` — вернуть сжатое представление `X_new` для обученной ранее модели;\n","* `inverse_transform(Y)` — восстановить сжатые данные `Y` в исходное пространство.\n","\n","Атрибуты класса:\n","\n","* `components_` — главные компоненты в порядке убывания собственных чисел, размер (n_components, n_features);\n","* `explained_variance_` — дисперсия вдоль главных компонент, равны собственным числам, размер (n_components,);\n","* `explained_variance_ratio_` —- доля дисперсии, объясняемая каждой компонентой, размер (n_components,);\n","* `mean_` — среднее по данным, размер (n_components,);\n","* `noise_variance_` — оценка дисперсии шума для метода Probabilistic PCA.\n","\n","Другие модификации, реализованные в sklearn:\n","\n","* <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA\">`KernelPCA`</a>;\n","* <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA\">`SparsePCA`</a>;\n","* <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.IncrementalPCA\">`IncrementalPCA`</a>."],"metadata":{"id":"BElBOBKHEcjC"}},{"cell_type":"markdown","metadata":{"id":"_ijs7O0qq5GT"},"source":["Для демонстрации работы PCA сгенерируем двумерный датасет из нормального распределения."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-20T09:04:25.956789Z","start_time":"2021-02-20T09:04:25.942439Z"},"id":"ZBBmCNaCq5GW"},"source":["# Сгенерируем двухмерный датасет при помощи функции multivariate_normal из модуля random библиотеки numpy\n","# Например, размера 150, со средними [0,3] и ковариацией [[3, 1], [1, 1]]\n","\n","X = ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Почему мы просто не воспользовались `np.random.normal`, как в прошлом примере?"],"metadata":{"id":"JN7qYY6sRwWO"}},{"cell_type":"code","metadata":{"id":"v9_y40xcLaF2"},"source":["# Посмотрим, что матрица того размера, который мы предполагали\n","..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-20T09:04:25.971396Z","start_time":"2021-02-20T09:04:25.958785Z"},"id":"7jMA2XwXq5Gj"},"source":["# Создадим объект класса PCA с числом компонент, равным 1\n","pca = ..."],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Обучим и преобразуем нашу матрицу X при помощи метода fit_transform\n","Y = ..."],"metadata":{"id":"wj6qWTn8TBVV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Преобразуем наши данные в исходнрый размер при помощи метода inverse_transform\n","# Это можно понять следующий образом: если SVD возвращает U, S, V и U@S -- это PCA преобразование\n","# То множение еще и на V, то это обратное преобразование\n","\n","X_hat = ..."],"metadata":{"id":"KAVQGdqQTBXY"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lddJLpAvLqAY"},"source":["# Выведем размеры матриц X, Y и X_hat\n","print(...)\n","print(...)\n","print(...)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-20T09:04:25.979961Z","start_time":"2021-02-20T09:04:25.974470Z"},"id":"rpBuWAIRq5Gl"},"source":["# Посмотрим на главные компоненты (точнее, одну компоненту) при помощи переменную components_\n","..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-20T09:04:25.992390Z","start_time":"2021-02-20T09:04:25.982678Z"},"id":"4H9RUpvjq5Gm"},"source":["# Посомтрим на вектор средних, вызвав переменную mean_\n","..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c3fx4Kzzq5Gn"},"source":["Построим следующие графики: \n","* На первом графике синим отмечены исходные точки, красным - они же после проецирования и обратного преобразования.\n","\n","* На втором графике точки, спроецированные на главную компоненту в одномерном пространстве. Иными словами распределение точек вдоль главной компоненты."]},{"cell_type":"code","source":["fig, axes = plt.subplots(ncols=1, nrows=2, figsize=(12, 8), sharex=True, gridspec_kw={'height_ratios': [4, 1]})\n","\n","# Отрисуем точки, поспользовавшись первой колонкой матрицы X как координатами точек по оси х\n","# и второй колонкой как координатами точек по оси y\n","axes[0].scatter(..., ..., alpha=0.7, color=blue)\n","# Аналогично с преобразованной матрицей X_hat\n","axes[0].scatter(..., ..., color=red, alpha=0.7)\n","\n","axes[0].set_xlabel('Исходный признак 1')\n","axes[0].set_ylabel('Исходный признак 2')\n","\n","# Отрисуем распределения точек вдоль главной компоненты, передав в качестве координат по оси x вектор -Y\n","# (подумайте почему в нашем случае -Y, а не Y. Подсказка -- посмотрите на главную компоненту),\n","# а в качестве координат по оси y нули\n","axes[1].scatter(..., ..., alpha=0.5, color=red)\n","\n","axes[1].set_xlabel('Проекция на первую главную компоненту')\n","\n","plt.show()"],"metadata":{"id":"i3pPCS_3oanQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"khZlPOdYq5HB"},"source":["Другие методы снижения размерности:\n","\n","* http://scikit-learn.org/stable/modules/manifold.html#manifold\n","\n","Примеры с визуализацией:\n","\n","* http://scikit-learn.org/stable/auto_examples/manifold/plot_compare_methods.html#sphx-glr-auto-examples-manifold-plot-compare-methods-py\n","\n","* http://scikit-learn.org/stable/auto_examples/manifold/plot_manifold_sphere.html#sphx-glr-auto-examples-manifold-plot-manifold-sphere-py"]},{"cell_type":"markdown","source":["## 3. Cжатие изображений с помощью PCA"],"metadata":{"id":"A7BEraabhWFC"}},{"cell_type":"code","source":["# Скачаем картинку\n","! wget https://www.dropbox.com/s/ehhrw5l46rpnv61/3840x2400.png"],"metadata":{"id":"iRYT8urpXo_z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Считаем картинку при помощи функции imread библиотеки matplotlib\n","image = ..."],"metadata":{"id":"5dvr5_TphlBz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Посмотрим какой размер изображения. За что отвечает каждая размерность?\n","..."],"metadata":{"id":"jhzX-syBuLHV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Посмотрим что из себя представляет image\n","..."],"metadata":{"id":"-FgLMgQyhpST"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Отрисуем картику при помощи функции imshow библиотеки matplotlib\n","..."],"metadata":{"id":"i9KT6qZPh5_e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Что предлагается сделать:**\n","\n","Давайте разобьем наше изображение на 24 равных кусочка (нарежем изображение на равные части). \n","\n","Применим к картинке преобразования для выделения 24 блоков размера 600x640. То есть из массива `(2400, 3840, 3)` сделаем массивом `(24, 600, 640, 3)`, чтобы потом каждый кусочек растянуть в один вектор, то есть получить массив `(24, 600 * 640 * 3)`\n","\n","Для этого мы будем использовать простую логику: если мы хотим разделить какую-то размерность(например из 2400 сделать 4 и 600), то мы должны перенести ее в конец, а если мы хотим соединить две размерности (из 4 и 600 сделать 2400), то мы также должны перенести их обе в конец друг за другом.\n","\n","Для этого нам нужны две функции:\n","* Для переноса размерностей используют метод `transpose(<на какую позицию переместить нулевую размерность>, <на какую позицию переместить первую размерность>, и т.д.)`;\n","* Для склейки и разделения размерностей используют метод `reshape(<новый размер>)`."],"metadata":{"id":"U71TZ_cXiCO_"}},{"cell_type":"code","source":["# Размерность изначального изображения\n","image.shape"],"metadata":{"id":"GLelbgRsh73m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Размерность после перестановки нулевой оси на первую позицию, первой на вторую, а вторую на нулевую\n","image.transpose((1, 2, 0))\\\n","    .shape"],"metadata":{"id":"15W4HLkih79_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Разбиваем высоту и посмотрим размерность\n","image.transpose((1, 2, 0))\\\n","    .reshape((3840, 3, 4, 600))\\\n","    .shape "],"metadata":{"id":"g8YIWBhmh8AY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Переставляем размерности, чтобы разбить ширину и смотрим размерность\n","image.transpose((1, 2, 0))\\\n","    .reshape((3840, 3, 4, 600))\\\n","    .transpose((1, 2, 3, 0))\\\n","    .shape "],"metadata":{"id":"m5y1h-_Vh8CL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Разбиваем ширину и смотрим размерность\n","image.transpose((1, 2, 0))\\\n","    .reshape((3840, 3, 4, 600))\\\n","    .transpose((1, 2, 3, 0))\\\n","    .reshape((3, 4, 600, 6, 640))\\\n","    .shape "],"metadata":{"id":"3xoAZxovizH5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Переставляем размерности, чтобы схлопнуть размерности\n","image.transpose((1, 2, 0))\\\n","    .reshape((3840, 3, 4, 600))\\\n","    .transpose((1, 2, 3, 0))\\\n","    .reshape((3, 4, 600, 6, 640))\\\n","    .transpose((1, 3, 2, 4, 0))\\\n","    .shape "],"metadata":{"id":"laxiXEi7izNd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# И наконец склеиваем размерности, чтобы получить 24 строки и смотрим какие получились размерности\n","image.transpose((1, 2, 0))\\\n","    .reshape((3840, 3, 4, 600))\\\n","    .transpose((1, 2, 3, 0))\\\n","    .reshape((3, 4, 600, 6, 640))\\\n","    .transpose((1, 3, 2, 4, 0))\\\n","    .reshape((4 * 6, 600 * 640 * 3))\\\n","    .shape "],"metadata":{"id":"xWTe5EZ1izPo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ура, мы справились с этой довольно сложной задачей! Давайте теперь соберем все вместе."],"metadata":{"id":"nnSjlUqjyjrn"}},{"cell_type":"code","source":["# Итого:\n","X = ...\n","print(X.shape)\n","# На самом деле мы получили в некотором смысле матрицу объект-признак для нашего изображения\n","# Ведь если так подумать, то объектом для картинки является ее кусочек, а признаками какое-то \n","# Представление кусочков"],"metadata":{"id":"-kXdu42HjCuS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Визуализируем получившиеся блоки, чтобы понять, что мы нигде не ошиблись\n","# Если у нас сложится целая картинка, то все сделано верно\n","\n","plt.figure(figsize=(11, 7))\n","for i in range(24):\n","    plt.subplot(4, 6, i + 1)\n","    plt.imshow(X[i].reshape((600, 640, 3)))\n","    plt.axis('off');\n","\n","# Как видим, все правильно."],"metadata":{"id":"mWRuatWLjCwq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Воспользуемся следующими функциями, что исследовать влияние выбора числа главных компонент на качество изображения.\n","\n","Вспомните -- ведь мы можем выбрать число компонент (тем самым усекая матрицы в SVD разложении), которые хотим оставить и потом возвращаться в исходные размеры, домножая на третью усеченую матрицу в SVD разложении."],"metadata":{"id":"iINTgk6MjPfM"}},{"cell_type":"code","source":["# Итак, посмотрим, что делают предложенные функции\n","def draw_components(pca, n, m):\n","    \"\"\"\n","    Функция отрисовывает главные компоненты по обученной PCA модели\n","\n","    pca - обученная PCA модель\n","    n - количество горизонтальных блоков картинки\n","    m - количество вертикальных блоков картинки\n","    \"\"\"\n","    print('Среднее изображение')\n","    plt.figure(figsize=(1, 1))\n","    plt.imshow(pca.mean_.reshape((n, m, 3)), cmap='gray')\n","    plt.axis('off')\n","    plt.show()\n","\n","    print('Главные компоненты')\n","    plt.figure(figsize=(11, len(pca.components_) // 10 + 1))\n","    for i, comp in enumerate(pca.components_):\n","        plt.subplot(len(pca.components_) // 10 + 1, 10, i + 1)\n","        img = pca.components_[i].reshape((n, m, 3))\n","        plt.imshow((img - img.min()) / (img.max() - img.min()), cmap='gray')\n","        plt.axis('off')\n","    plt.show()\n","\n","        \n","def image_pca(image, n, m, n_components=20, draw_picture=True, \n","              draw_comp=True, visualization=True):\n","    \"\"\"\n","    Функция сжимает изображение согласно заданному числу главных компонент, а затем \n","    возвращает в исходный вид и рисует результат.\n","\n","    image - исходаня картинка\n","    n - количество горизонтальных блоков картинки\n","    m - количество вертикальных блоков картинки\n","    n_components - количество главных компонент\n","    draw_picture - показывать ли исходную картинку\n","    draw_comp - рисовать ли главные компоненты\n","    visualization - рисовать ли проекцию на первые три компоненты\n","    \"\"\"\n","\n","    # Показываем исходную картинку\n","    if draw_picture:\n","        plt.figure(figsize=(15, 7))\n","        plt.imshow(image)\n","        plt.axis('off')\n","        plt.show()\n","    print(\"Размерность оригинальной картинки: \", image.shape)\n","    \n","    # Разбиение на блоки\n","    N, M, K = image.shape\n","    X = image.transpose((1, 2, 0))\\\n","             .reshape((M, K, N // n, n)) \\\n","             .transpose((1, 2, 3, 0))\\\n","             .reshape((K, N // n, n, M // m, m)) \\\n","             .transpose((1, 3, 2, 4, 0))\\\n","             .reshape((N * M // (n * m), n * m * K))   \n","    \n","    # Применение PCA\n","    pca = PCA(n_components=n_components)\n","    Y = pca.fit_transform(X)\n","    X_hat = pca.inverse_transform(Y)\n","    \n","    # Разбираемся с интенсивностью цвета\n","    max_value = X.max()\n","    X_hat = X_hat * (X_hat <= max_value) + max_value * (X_hat > max_value)\n","    X_hat = X_hat * (X_hat >= 0)\n","    \n","    # Собираем картинку из блоков\n","    X_hat = X_hat.reshape((N // n, M // m, n, m, K)).transpose((1, 3, 4, 0, 2))\\\n","                 .reshape((M // m, m, K, N)).transpose((3, 2, 0, 1))\\\n","                 .reshape((N, K, M)).transpose((0, 2, 1))\n","    \n","    # Рисуем восстановленную картинку\n","    plt.figure(figsize=(15, 7))\n","    plt.imshow(X_hat)\n","    plt.axis('off')\n","    plt.title('Восстановленное изображение при {} главных компонентах.\\n'.format(n_components))\n","    plt.show()\n","    print(\"Размерность сжатой картинки: \", X_hat.shape)\n","    \n","    # Если нужно, рисуем главные компоненты \n","    if draw_comp:\n","        draw_components(pca, n, m)\n","    \n","    # Визуализируем проекцию на первые три компоненты (третья - цвет)\n","    if visualization:\n","        pca = PCA(n_components=3)\n","        Y = pca.fit_transform(X)\n","        plt.figure(figsize=(15, 10))\n","        plt.scatter(Y[:, 0], Y[:, 1], c=Y[:, 2], alpha=0.1)\n","        plt.xlabel('Проекция на первую главную компоненту')\n","        plt.ylabel('Проекция на вторую главную компоненту')\n","        plt.title('Проекция на первые три компоненты (третья - цвет)')\n","        plt.show()\n","    plt.imsave('im1.png', image)\n","    print(\"Размер оригинального файла\", os.path.getsize('im1.png'))\n","\n","    plt.imsave('im2.png', X_hat)\n","    print(\"Размер сжатого файла\", os.path.getsize('im2.png'))"],"metadata":{"id":"UFcttvxfjCy3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Воспользуемся функцией image_pca и будем разбивать изображение на 12 секций по горизонтали на 16 секций по вертикале\n","..."],"metadata":{"id":"KaFWxG3YjRZ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Посмотрим как будет менять изображение в зависимости от разного числа собственных векторов\n","for n_components in [15, 10, 5, 4, 3, 2, 1]:\n","    image_pca(\n","        image, 12, 16, \n","        n_components=n_components, \n","        draw_picture=False,\n","        draw_comp=False, \n","        visualization=False\n","    )"],"metadata":{"id":"30yJjrWpjRcZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Вот так можно производить сжатие изображения при помощи PCA.\n","Но на самом деле это можно делать и со звуком и с видео, ведь все это можно представить как матрицы и от нас требуетсся только править выделить из этих матриц объекты и признаки, чтобы применить PCA!"],"metadata":{"id":"KkFaB9Ko3Pf7"}},{"cell_type":"markdown","source":["## 4. PCA для MNIST"],"metadata":{"id":"gdWdZsOyj34a"}},{"cell_type":"markdown","source":["Однако PCA нас интересует все же как способ уменьшения размерности данных, а не метод сжатия данных.\n","\n","Поэтому предлагается применить его для решения задачи классификации на датасете MNIST, который представляет из себя изображения нарисованных от руки цифр и меток, какая именно цифра нарисована. То есть необходимо решить задачу многоклассовой классификации."],"metadata":{"id":"8V_pQUO13kIh"}},{"cell_type":"code","source":["# Скачаем тренировочные данные\n","! wget https://www.dropbox.com/s/gq1tj9bzj8dkcul/mnist_train.csv"],"metadata":{"id":"rIZ_2NjHjC1Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Загрузим данные mnist_train.csv при помощи функции read_csv библиотеки pandas\n","mnist_data_all = ..."],"metadata":{"id":"QL0CygMNp-M0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Посмотрим на данные. Что является таргетом и в какой колонке он находится?\n","..."],"metadata":{"id":"8sgynsvf4azv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Разделим данные на признаки и метки\n","mnist_label = ...\n","mnist_data = ..."],"metadata":{"id":"QBFDKSnNqKbF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Посмотрим на размер признаков. Почему их именно столько? Как это связано с обещанными картинками?\n","..."],"metadata":{"id":"WKY53JD2qKdW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Выведем метку какого-нибудь элемента и отрисуем его при помощи функции imshow библиотеки matplotlib\n","plt.figure(figsize=(6,5))\n","\n","idx = ...\n","\n","print(\"Label: \", ...)\n","\n","# Необходимо выбрать объект, конвертировать его в numpy, а затем сделать reshape() в нужный размер\n","grid_data = ...\n","plt.imshow(grid_data, interpolation = \"none\", cmap = \"gray\")\n","plt.show()"],"metadata":{"id":"mEJwIypcqKhS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["В нашем датасете каждый объект описывается 784 фичами. Как нам одним взглядом посмотреть на весь датасет? \n","\n","К нам на помощь опять приходит PCA!"],"metadata":{"id":"Tr-PUAm1qTja"}},{"cell_type":"code","source":["# Создадим объект класса PCA с числом компонент, равным 2 (чтобы отрисовать точки на плоскости)\n","pca = ..."],"metadata":{"id":"4cjNhO8xqUQP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Обучим PCA на наших признаках при помощи метода fit\n","..."],"metadata":{"id":"Tubynw2uqUwm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Трансформируем наш датасет в 2d при помощи метода transform\n","mnist_data_2D = ..."],"metadata":{"id":"gpZL7PdvqUyy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Посмотрим на размер получившегося датасета\n","..."],"metadata":{"id":"A62LItO5qaYo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Отрисуем точки на плоскости при помощи функции scatter и зададим им цвет согласно их классу передав в аргумент c=mnist_label\n","plt.figure(figsize=(10,8))\n","\n","...\n","\n","plt.colorbar()\n","plt.show()"],"metadata":{"id":"GbQnduY4qafY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Зачем нам вообще нужно уменьшать число признаков? Верно, у нас есть проклятье размерности, но что это для нас значит с точки зрения людей, которые работают с данными?\n","\n","**Проклятие размерности**\n","\n","Большая размерность приводит к следующим проблемам:\n","\n","*   Нужно много памяти.\n","*   Трудоемкие вычисления.\n","*   Все элементы выборки начинают находится примерно на одинаковом расстоянии друг от друга!\n","\n"],"metadata":{"id":"jiiK8z95qkvw"}},{"cell_type":"markdown","source":["Мы можем продемострировать как большое число (зачастую шумовых) признаков влияет на работу алгорима машинного обучения. Для этого мы решим задачу классфикации на датасете MNIST с применением алгоритма PCA в качестве метода уменьшения размерности."],"metadata":{"id":"_TOVn-5JrFoZ"}},{"cell_type":"code","source":["# Скачаем тестовые данные\n","! wget https://www.dropbox.com/s/xuya93ez6ff712x/mnist_test.csv"],"metadata":{"id":"yA1Ub14xrCNg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Загрузим данные mnist_test.csv при помощи функции read_csv библиотеки pandas\n","mnist_data_test_all = ..."],"metadata":{"id":"on6YYaAdrEOA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Разделим признаки и метки\n","mnist_label_test = ...\n","mnist_data_test = ..."],"metadata":{"id":"6utypzrMrQOh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Посморим на размер тестового датасета\n","..."],"metadata":{"id":"X_QgojzfrQQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Будем решать задачу при помощи алгоритма ближайших соседей, поэтому импортируем этот алгоритм из sklearn\n","from sklearn.neighbors import KNeighborsClassifier"],"metadata":{"id":"0oEWnQN8rUxG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Воспользуемся следующей функцией -- она принимает тренировочный и тестовый датасет и число компонентв в PCA, преобразуют данные\n","# обучает модель и возвращает качество на тестовом датасете\n","def reduce_and_learn(X_train, y_train, X_test, y_test, dim=2):\n","    pca = PCA(n_components=dim)\n","    \n","    pca.fit(X_train)\n","    X_train_dim_D = pca.transform(X_train)\n","\n","    knn = KNeighborsClassifier(n_neighbors=5)\n","    knn.fit(X_train_dim_D, y_train)\n","\n","    X_test_dim_D = pca.transform(X_test)\n","\n","    predict_quality = knn.score(X_test_dim_D, y_test)\n","    return predict_quality"],"metadata":{"id":"4ioGeVrHrUy-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dims = [2, 5, 10, 20, 40, 80, 160, 320, 640, 784]\n","predicts_quality = []\n","\n","# В цикле по числу компонент, запускаем функцию reduce_and_learn и сохраняем качество в массив predicts_quality\n","for dim in dims:\n","    predicts_quality.append(...)"],"metadata":{"id":"NqPRQ5b3rigW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Отрисуем зависимость качества от числа компонент в PCA\n","plt.figure(figsize=(10,8))\n","\n","...\n","\n","plt.rc('font', size=12)\n","plt.xlabel('Размерность')\n","plt.ylabel('Качество предсказания')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"RhaqM0TYriiu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Выведем число компонент при котором качество максимально и максимальное качество\n","print(f\"Лучшее качество при {...} компонентах\")\n","print(f\"Максимальное качество = {...}\")"],"metadata":{"id":"vo6DHANPrikx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Мы получили не большой прирост (но все же прирост), но даже он может уменьшать убытки компании на миллионы. Кроме того, другие алгоритмы могут иметь большую разницу в качестве и такие эксперименты предлагаются слушателю в качестве упражнения.\n","\n","Кроме того, вы наверняка заметили разницу в скорости работы алгоритмов с разным числом признаков. Часто скорость работы является одним из важнейших пунктов выбора алгоритма и набора признаков."],"metadata":{"id":"xnsSbGyo-ShS"}}]}